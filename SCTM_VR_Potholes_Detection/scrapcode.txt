const int MAX_VALUE = 255;
const int MAX_TYPE = 4;
const int MAX_BINARY_VALUE = 255;
const int BIN_THS_VALUE = 100;

//int threshold_value = 100;
//Mat BW = Mat();
//cvtColor(image, BW, COLOR_RGB2GRAY);
//Mat bin = Mat();
//threshold(BW, bin, 100, MAX_BINARY_VALUE , BINARY);
//Mat mid = Mat();
//medianBlur(bin, mid, 3);
//Mat dilated = Mat();
//Mat str_el = getStructuringElement(MORPH_ELLIPSE, Size(2 * 1 + 1, 2 * 1 + 1), Point(1, 1));
//dilate(mid, dilated, str_el);
//namedWindow("display window", WINDOW_AUTOSIZE);    // create a window for display.
//imshow("display window", dilated);                     // show our image inside it.
//waitKey(0);
//bilateralFilter(tmp1, tmp2, blur_strength, blur_strength*2, blur_strength*0.5);

//    Mat ft_data = ConvertFeatures(features);
//
//    cv::PCA pca(ft_data, Mat(), PCA::DATA_AS_ROW);
//
//    Mat compressed_data;
//    pca.project(ft_data, compressed_data);
//
//    normalize(compressed_data, compressed_data, 1, 0, cv::NORM_L2);
//
//    cout << "REDUCED FEATURES n*2: " << endl;
//
//    for (int i = 0; i < features.size(); ++i) {
////        cout
////             << " \t " << compressed_data.at<float>(i, 0)
////             << ",\t " << compressed_data.at<float>(i, 1)
////             << ",\t " << compressed_data.at<float>(i, 2)
////             << ",\t " << compressed_data.at<float>(i, 3)
////             << ",\t " << compressed_data.at<float>(i, 4)
////             << ",\t " << features[i].label
////             << ",\t " << names[i]
////             << endl;
//    }
//
//    FileStorage pca_save_file;
//    pca_save_file.open("../data/pca_model.yml", FileStorage::Mode::APPEND);
//    pca.write(pca_save_file);
//    pca_save_file.release();

float RGBMean(const Mat &src) {

    float meanR = 0.0f;
    float meanG = 0.0f;
    float meanB = 0.0f;

    float bias = src.rows * src.cols * 3;

    for (int r = 0; r < src.rows; ++r) {
        for (int c = 0; c < src.cols; ++c) {
            auto pixel = src.at<Vec3i>(r, c);
            meanB += pixel.val[0];
            meanG += pixel.val[1];
            meanR += pixel.val[2];
        }
    }

    return (meanB + meanG + meanR) / bias ;
}

float RGBStandardDeviation(const Mat &src) {

    float stdB = 0.0f;
    float stdG= 0.0f;
    float stdR = 0.0f;
    float bias = src.rows * src.cols * 3 - 1;
    float mean = RGBMean(src);

    for (int r = 0; r < src.rows; ++r) {
        for (int c = 0; c < src.cols; ++c) {
            auto pixel = src.at<Vec3i>(r, c);
            stdB += (pixel.val[0] - mean) * (pixel.val[0] - mean);
            stdG += (pixel.val[1] - mean) * (pixel.val[1] - mean);
            stdR += (pixel.val[2] - mean) * (pixel.val[2] - mean);
        }
    }

    return sqrtf((stdB + stdG + stdR) / bias);
}

void RoadSegmentation(Mat &src, Mat &out) {

    Size scale(RESIZING_WIDTH, RESIZING_HEIGHT);
    resize(src, src, scale);

    out = Mat::zeros(src.rows, src.cols, CV_32SC1);

    float std = RGBStandardDeviation(src);

    cout << "STD: " << std << endl;

    for (int row = 0; row < src.rows; ++row) {
        for (int col = 0; col < src.cols; ++col) {
            auto pixel = src.at<Vec3i>(row, col);
            if (pixel.val[1] - (pixel.val[0] + pixel.val[2]) * 0.5f + 15 > 0 ||
                    pixel.val[2] - pixel.val[0] > 20 ||
                    pixel.val[1] - pixel.val[2] > 15) {

                out.at<int>(row, col) = 0;

            } else if (
                    ((pixel[0] + pixel[1] + pixel[2]) / 3.0f > 255 - std) ||
                    ((pixel[0] + pixel[1] + pixel[2]) / 3.0f < std)
                    ) {

                out.at<int>(row, col) = 0;

            } else if (pixel[0] > 0 && pixel[1] > 0 && pixel[2] > 0) {

                out.at<int>(row, col) = 255;

            }
        }
    }
}



void create_training_set_by_row(const vector<Mat> & set, Mat & training_set) {

	for (int i = 0; i < set.size(); ++i) {
		Mat img;
		set[i].convertTo(img, CV_32FC1);
		training_set.push_back(img.reshape(0, 1));
	}
}

void Bayes() {

	vector<Mat> set;
	Mat training_set, classes, tmp;
	vector<string> ids;

	load_from_directory(positive_training_set_directory, ids, set, classes, CLASSES::POTHOLE, IMREAD_GRAYSCALE);
	load_from_directory(negative_training_set_directory, ids, set, classes, CLASSES::NORMAL, IMREAD_GRAYSCALE);

	create_training_set_by_row(set, tmp);

	cout << tmp.size() << " --- " << classes.size() << endl;

	Ptr<NormalBayesClassifier> Bayes = NormalBayesClassifier::create();

	cout << "Starting training... ";
	
	tmp.convertTo(training_set, CV_32FC1);
	
	cout << training_set.type() << endl;

	Bayes->train(training_set, SampleTypes::ROW_SAMPLE, classes);

	cout << "Saved Trained Classifier @ " << classifier64 << endl;

	Bayes->save(classifier64);
}

// All the values are reffered top-down for verticals and right to left for horizontals
void ApplyFixedRoadLinesAndHorizon(const double V_offset = 0.95, const double H_offset = 0.00, const double Cutline_offset = 0.50, const double VP_offset_X = 0.50, const double VP_offset_Y = 0.30) {
	
	vector<Mat> set;
	Mat classes;
	vector<string> ids;
	
	Scalar filling_color(0, 0, 0);
	Size window(90, 60);
	double blur_strength = 7.0;

	load_from_directory(positive_directory, ids, set, classes, CLASSES::POTHOLE);
	load_from_directory(negative_directory, ids, set, classes, CLASSES::NORMAL);

	for (int i = 0; i < set.size(); ++i) {
		
		Mat tmp0, tmp1;
		vector<Vec2f> lines;

		set[i].copyTo(tmp0);

		cvtColor(tmp0, tmp0, CV_RGB2GRAY);

		// Fill roadside with mask
		Point left_roadside[1][3] = {
			{Point(0, 0), Point(tmp0.cols*VP_offset_X, tmp0.rows*VP_offset_Y), Point(0, tmp0.rows*V_offset)}
		};

		Point right_roadside[1][3] = {
			{Point(tmp0.cols*VP_offset_X, tmp0.rows*VP_offset_Y), Point(tmp0.cols - 1, tmp0.rows*V_offset), Point(tmp0.cols - 1, 0)}
		};

		fillConvexPoly(tmp0, left_roadside[0], 3, filling_color);
		fillConvexPoly(tmp0, right_roadside[0], 3, filling_color);

		cout << "Cutting @ horizon..." << endl;

		tmp0 = tmp0(Rect(Point(0, tmp0.rows*Cutline_offset), Point(tmp0.cols - 1, tmp0.rows - 1)));	

		resize(tmp0, tmp1, window);
		
		string masks_save_location = train_home_directory + (classes.at<int>(i) == 1 ? "Train\\Positive\\" : "Train\\Negative\\") + "Masks\\" + ids[i];

		set_format(masks_save_location, "bmp");

		imwrite(masks_save_location, tmp1);

		cout << "Saved Roadmask @ " << masks_save_location << endl;

		/************************************************************************************************************************************/

		//Canny(tmp0, tmp1, 50, 150);

		threshold(tmp1, tmp1, 150, 255, THRESH_OTSU | THRESH_BINARY_INV);

		string bin_save_location = train_home_directory + (classes.at<int>(i) == 1 ? "Train\\Positive\\" : "Train\\Negative\\") + "Masks\\" + ids[i];

		set_format(bin_save_location, "bmp");

		imwrite(bin_save_location, tmp1);

		cout << "Saved ths @ " << bin_save_location << endl;

		tmp0.release();
		tmp1.release();

		set[i].release();

		/************************************************************************************************************************************/
	}

	classes.release();
}

struct Box {
	Point2i bottom_right;
	Point2i top_left;

	bool contains(Point2i);
};

struct Annotation {

	string image_path;
	string image_name;
	vector<Box> objects;

};

bool Box::contains(Point2i p) {
	return p.x <= this->bottom_right.x && p.x >= this->top_left.x && p.y <= this->bottom_right.y && p.y >= this->top_left.y;
}

/*
Mat BW = Mat();
cvtColor(image, BW, COLOR_RGB2GRAY);

Mat bin = Mat();
threshold(BW, bin, BIN_THS_VALUE, MAX_BINARY_VALUE , THRESH_BINARY_INV | THRESH_OTSU);
*/
/*****************************************************************************************************************/

//Ptr<AKAZE> akaze_descr = AKAZE::create();
//vector<KeyPoint> kps;
//Mat descriptor = Mat();
//string akaze_descr_save_path = data_root_path + "keypoints/akaze/" + image_name;
//set_format(akaze_descr_save_path, "yml");
//FlannBasedMatcher flann_matcher= FlannBasedMatcher();
//clog << "Compuing Akaze descritor for " << image_name << " ... ";
//akaze_descr->detectAndCompute(image, Mat(), kps, descriptor);
//clog << akaze_descr_save_path << endl;
//akaze_descr->write(akaze_descr_save_path);
//clog << "Saved akaze descriptor of " << image_name << " as " << akaze_descr_save_path << endl;

//Mat kps_image;
//drawKeypoints(image, kps, kps_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
//imshow("Keypoints", kps_image);
//waitKey(0);

void labeling(const vector<Mat> & images, Mat & training_set, Mat & classes_set, const vector<Annotation> & annotations = vector<Annotation>(), bool use_annotations = false)
{
	for (size_t i = 0; i < images.size(); ++i)
	{

		Mat image = images[i];
		vector<Box> windows = annotations[i].objects;
		Mat classes(image.rows, image.cols, CV_32FC1);

		for (size_t row = 0; row < image.rows; ++row)
		{

			for (size_t col = 0; col < image.cols; ++col)
			{

				for (size_t w = 0; w < windows.size(); ++w)
				{

					if (windows[w].contains(Point2i(row, col)))
					{
						classes.at<int>(row, col) = CLASSES::POTHOLE;
					}
					else
					{
						classes.at<int>(row, col) = CLASSES::BACKGROUND;
					}
				}
			}
		}

		image.convertTo(image, CV_32FC1);

		training_set.push_back(image.reshape(1, 1));
		classes_set.push_back(classes.reshape(1, 1));
	}
}

vector<string> CSVTokenizer(const string str, const char delimiter) {

    // Delete spaces
    string tmp(str);
    auto end_pos = remove(tmp.begin(), tmp.end(), ' ');
    tmp.erase(end_pos, tmp.end());
    end_pos = remove(tmp.begin(), tmp.end(), '\"');
    tmp.erase(end_pos, tmp.end());

    // Detect arrays
    auto array_start = tmp.find_first_of('[');
    auto array_end = tmp.find_first_of(']');

    vector<string> tokens;
    auto offset = array_start > 0 && array_start < tmp.size() ? array_start - 2 : tmp.size(); // jump over ",["
    std::istringstream iss(tmp.substr(0, offset));
    string token;
    while (std::getline(iss, token, delimiter)) tokens.push_back(token);

    if (array_start > 0 && array_start < tmp.size()) {
        auto v = tmp.substr(array_start + 1, array_end - 1);
        tokens.push_back(v);
    }

    return tokens;
}

Features objectify(const vector<string> &headers, const vector<string> &tokens, Mat &labels) {

    Features ft;

    for (int i = 0; i < tokens.size(); ++i) {
        const string header = headers[i];

        if (header == "class") {
            labels.push_back(stoi(tokens[i]));
        } else if (header == "contrast") {
            ft.contrast = stof(tokens[i]);
        } else if (header == "skewness") {
            ft.skewness = stof(tokens[i]);
        } else if (header == "avggreyval") {
            ft.averageGreyValue = stof(tokens[i]);
        } else if (header == "energy") {
            ft.energy = stof(tokens[i]);
        } else if (header == "entropy") {
            ft.entropy = stof(tokens[i]);
        } else if (header == "hog") {

            auto array_values = CSVTokenizer(tokens[i], ',');
            ft.hogDescriptors = Mat1f(1, static_cast<int>(array_values.size()));
            for (int j = 0; j < array_values.size(); ++j) {
                ft.hogDescriptors.at<float>(0, j) = stof(array_values[j]);
            }
        }
    }

    return ft;
}

void loadFromCSV(const string target, vector<Features> &ft, Mat &labels) {

    ifstream csv(target);

    if (csv.is_open()) {

        cout << "Opened file " << target << endl;

        string line;
        // Get Headers;
        std::getline(csv, line);
        std::transform(line.begin(), line.end(), line.begin(), ::tolower);
        // Do something with headers ...
        vector<string> headers = CSVTokenizer(line, ',');

        for (auto str : headers) cout << str << " ";

        cout << endl;

        while (std::getline(csv, line)) {

            vector<string> tokens = CSVTokenizer(line, ',');

            auto f = objectify(headers, tokens, labels);

            ft.push_back(f);
        }
        csv.close();
    } else {
        cerr << "Unable to open file " << target << endl;
    }

    cout << labels.rows << " " << ft.size() << endl;

}


bool checkExistence(const string &target) {

    ifstream csv(target);

    if (csv.is_open()) {
        string line;
        std::getline(csv, line);

        // Normalize the string.
        auto end_pos = remove(line.begin(), line.end(), ' ');
        line.erase(end_pos, line.end());
        std::transform(line.begin(), line.end(), line.begin(), ::tolower);

        cout << line << endl;
        if (line == "class,candidate,contrast,skewness,avggreyval,energy,entropy,hog") {
            return true;
        }

        csv.close();
    } else {
        cerr << "Unable to open file " << target << ". It may not exist!" << endl;
    }

    return false;
}

void saveFeaturesCSV(const vector<Features> &features, const string saveDirectory, const vector<string> names,
                     const string saveFile) {

    bool doesNotExist = !checkExistence("../" + saveDirectory + "/" + saveFile + ".csv");

    portable_mkdir(("../" + saveDirectory).data());

    ofstream csv("../" + saveDirectory + "/" + saveFile + ".csv", fstream::in | fstream::out | fstream::app);

    if (csv.is_open()) {

        if (doesNotExist) {
            csv << "Class,Candidate,Contrast,Skewness,AvgGreyVal,Energy,Entropy,HOG" << endl;
        }

        for (int i = 0; i < features.size(); ++i) {

            auto f = features[i];
            auto candidate = extractFileName(names[i]);

            string c_name = set_format(candidate, "", false) + "_L" + to_string(f.label);

            cout << "Saving candidate " << c_name << endl;

            csv << -1 << ",";
            csv << c_name << ",";
            csv << f.contrast << ",";
            csv << f.skewness << ",";
            csv << f.averageGreyValue << ",";
            csv << f.energy << ",";
            csv << f.entropy << ",";
            csv << "\"" << f.hogDescriptors << "\"" << endl;

            imwrite("../" + saveDirectory + "/" + c_name + ".bmp", f.candidate);

        }

        csv.close();
    } else {
        cerr << "Ops, we got a problem opening the feature file!" << endl;
    }
}